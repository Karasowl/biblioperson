# Gu√≠a de Loaders - Biblioperson

## Introducci√≥n

Los loaders son componentes fundamentales del sistema Biblioperson que se encargan de leer archivos en diferentes formatos y convertirlos en una estructura de datos com√∫n para su procesamiento. Esta gu√≠a detalla todos los loaders disponibles y c√≥mo utilizarlos.

## üèóÔ∏è Arquitectura de Loaders

### Concepto Base

Todos los loaders heredan de la clase `BaseLoader` y proporcionan un m√©todo `load()` que devuelve un iterador de documentos. Esta arquitectura permite:

- **Procesamiento uniforme** de diferentes formatos
- **Extensibilidad** para nuevos tipos de archivo
- **Consistencia** en la estructura de datos de salida
- **Eficiencia** mediante procesamiento por streaming

### Estructura de Datos Com√∫n

Cada loader produce documentos con la siguiente estructura:

```python
{
    'text': "Contenido textual del segmento",
    'is_heading': False,  # True si es un t√≠tulo/encabezado
    'fuente': "nombre_autor",  # Extra√≠do del directorio padre
    'contexto': "ruta/completa/al/archivo.ext",  # Ruta completa del archivo
    'fecha': "2023-12-01"  # Fecha extra√≠da o inferida
}
```

## üìÑ Loaders Disponibles

### üìù txtLoader

**Prop√≥sito**: Procesa archivos de texto plano (`.txt`)

**Caracter√≠sticas especiales**:
- **Detecci√≥n autom√°tica de t√≠tulo**: Si la primera l√≠nea est√° separada del resto
- **Extracci√≥n de fecha**: Del nombre del archivo con formatos reconocibles
- **Detecci√≥n de tipo**: Distingue entre poemas y prosa usando heur√≠sticas
- **Procesamiento l√≠nea por l√≠nea**: Mantiene estructura original

**Ejemplo de uso**:
```python
from dataset.processing.loaders import txtLoader

loader = txtLoader("ruta/al/archivo.txt", tipo='escritos', encoding='utf-8')
for documento in loader.load():
    print(f"Texto: {documento['text'][:50]}...")
    print(f"Es t√≠tulo: {documento['is_heading']}")
```

**Casos de uso ideales**:
- Archivos de texto simple
- Poemas y canciones
- Notas y apuntes
- Transcripciones

### üìã MarkdownLoader

**Prop√≥sito**: Procesa archivos Markdown (`.md`, `.markdown`)

**Caracter√≠sticas especiales**:
- **Preserva estructura Markdown**: Mantiene formato y jerarqu√≠a
- **Segmentaci√≥n inteligente**: Seg√∫n tipo de documento (escritos, poemas, canciones)
- **Extracci√≥n de metadatos**: Fecha del nombre o fecha de modificaci√≥n
- **Detecci√≥n de encabezados**: Identifica t√≠tulos y subt√≠tulos autom√°ticamente

**Ejemplo de uso**:
```python
from dataset.processing.loaders import MarkdownLoader

loader = MarkdownLoader("ruta/al/archivo.md", tipo='escritos', encoding='utf-8')
for documento in loader.load():
    if documento['is_heading']:
        print(f"üìå T√≠tulo: {documento['text']}")
    else:
        print(f"üìÑ Contenido: {documento['text'][:100]}...")
```

**Casos de uso ideales**:
- Documentaci√≥n t√©cnica
- Art√≠culos y ensayos
- Libros estructurados
- Contenido web

### üìä NDJSONLoader

**Prop√≥sito**: Procesa archivos NDJSON (JSON por l√≠nea)

**Caracter√≠sticas especiales**:
- **Procesamiento l√≠nea por l√≠nea**: Cada l√≠nea es un JSON independiente
- **Compatibilidad flexible**: Diferentes estructuras de datos JSON
- **Detecci√≥n autom√°tica de contenido**: Busca campos `texto`/`text`/`content`
- **Preservaci√≥n de metadatos**: Mantiene campos adicionales del JSON original

**Ejemplo de uso**:
```python
from dataset.processing.loaders import NDJSONLoader

loader = NDJSONLoader("ruta/al/archivo.ndjson", tipo='escritos', encoding='utf-8')
for documento in loader.load():
    print(f"Procesado: {documento['text'][:50]}...")
```

**Casos de uso ideales**:
- Datos de redes sociales (Twitter, Telegram)
- Logs estructurados
- Datasets existentes
- Mensajes y conversaciones

### üìÑ DocxLoader

**Prop√≥sito**: Procesa documentos Microsoft Word (`.docx`)

**Caracter√≠sticas especiales**:
- **Extracci√≥n de formato**: Preserva estructura de t√≠tulos y secciones
- **Procesamiento de estilos**: Detecta negrita, it√°lica, etc.
- **Metadatos del documento**: Extrae fecha de propiedades del archivo
- **Jerarqu√≠a de encabezados**: Identifica niveles de t√≠tulos autom√°ticamente

**Ejemplo de uso**:
```python
from dataset.processing.loaders import DocxLoader

loader = DocxLoader("ruta/al/archivo.docx", tipo='escritos', encoding='utf-8')
for documento in loader.load():
    nivel = "üìå" if documento['is_heading'] else "üìÑ"
    print(f"{nivel} {documento['text'][:80]}...")
```

**Casos de uso ideales**:
- Documentos acad√©micos
- Informes y reportes
- Libros y manuscritos
- Documentaci√≥n corporativa

### üìë PDFLoader

**Prop√≥sito**: Procesa documentos PDF (`.pdf`)

**Caracter√≠sticas especiales**:
- **Extracci√≥n de texto**: Mantiene estructura b√°sica de p√°rrafos
- **Metadatos PDF**: Procesa t√≠tulo, autor y propiedades del documento
- **Referencia de p√°gina**: Mantiene informaci√≥n de ubicaci√≥n
- **Manejo de formato**: Utiliza PyPDF2 para extracci√≥n robusta

**Ejemplo de uso**:
```python
from dataset.processing.loaders import PDFLoader

loader = PDFLoader("ruta/al/archivo.pdf", tipo='escritos', encoding='utf-8')
for documento in loader.load():
    print(f"üìñ P√°gina: {documento.get('page', 'N/A')}")
    print(f"üìÑ Texto: {documento['text'][:100]}...")
```

**Casos de uso ideales**:
- Libros digitales
- Art√≠culos cient√≠ficos
- Documentos oficiales
- Manuales t√©cnicos

### üìä ExcelLoader

**Prop√≥sito**: Procesa hojas de c√°lculo Excel (`.xlsx`, `.xls`, `.xlsm`)

**Caracter√≠sticas especiales**:
- **M√∫ltiples hojas**: Procesa todas las hojas del archivo
- **Estructura tabular**: Convierte filas y columnas a texto legible
- **Encabezados como t√≠tulos**: Usa nombres de hojas y columnas
- **Formato estructurado**: Convierte datos tabulares a narrativa

**Ejemplo de uso**:
```python
from dataset.processing.loaders import ExcelLoader

loader = ExcelLoader("ruta/al/archivo.xlsx", tipo='escritos', encoding='utf-8')
for documento in loader.load():
    if documento['is_heading']:
        print(f"üìä Hoja/Columna: {documento['text']}")
    else:
        print(f"üìã Datos: {documento['text']}")
```

**Casos de uso ideales**:
- Datos financieros
- Inventarios y cat√°logos
- Listas y registros
- An√°lisis y reportes

### üìà CSVLoader

**Prop√≥sito**: Procesa archivos CSV y TSV (`.csv`, `.tsv`)

**Caracter√≠sticas especiales**:
- **Detecci√≥n autom√°tica**: Identifica delimitadores (coma, punto y coma, tabulaci√≥n)
- **Encabezados inteligentes**: Procesa headers como t√≠tulos
- **Formato legible**: Convierte filas a formato "campo: valor"
- **Codificaci√≥n flexible**: Manejo inteligente de diferentes encodings

**Ejemplo de uso**:
```python
from dataset.processing.loaders import CSVLoader

loader = CSVLoader("ruta/al/archivo.csv", tipo='escritos', encoding='utf-8')
for documento in loader.load():
    print(f"üìä Registro: {documento['text']}")
```

**Casos de uso ideales**:
- Bases de datos exportadas
- Logs de aplicaciones
- Datos de investigaci√≥n
- Registros hist√≥ricos

## üîß ProfileManager

### ¬øQu√© es el ProfileManager?

El `ProfileManager` es el componente que facilita la selecci√≥n autom√°tica del loader adecuado basado en:

- **Extensi√≥n del archivo**
- **Perfil de procesamiento espec√≠fico**
- **Configuraci√≥n de contenido**
- **Umbrales de confianza**

### Uso B√°sico

```python
from dataset.processing.profile_manager import ProfileManager

manager = ProfileManager()

# Listar perfiles disponibles
perfiles = manager.list_profiles()
print("Perfiles disponibles:", perfiles)

# Procesar archivo autom√°ticamente
resultados = manager.process_file(
    "ruta/al/archivo.txt", 
    profile_name="book_structure",
    encoding="utf-8",
    force_content_type="escritos",  # Opcional: forzar tipo
    confidence_threshold=0.5        # Umbral para detecci√≥n autom√°tica
)

for resultado in resultados:
    print(f"Procesado: {resultado['text'][:50]}...")
```

### Configuraci√≥n Avanzada

```python
# Configurar perfil personalizado
manager.configure_profile("mi_perfil", {
    "segmentation_strategy": "paragraph",
    "min_segment_length": 50,
    "preserve_formatting": True,
    "extract_metadata": True
})

# Procesar con perfil personalizado
resultados = manager.process_file(
    "mi_documento.docx",
    profile_name="mi_perfil"
)
```

## üî® Extensi√≥n del Sistema

### Crear un Nuevo Loader

Para a√±adir soporte para un nuevo formato:

#### 1. Crear la Clase Loader

```python
from pathlib import Path
from typing import Iterator, Dict, Any, Optional
from .base_loader import BaseLoader

class MiNuevoLoader(BaseLoader):
    """Loader para formato personalizado."""
    
    def __init__(self, file_path: str | Path, tipo: str = 'escritos', encoding: str = 'utf-8'):
        super().__init__(file_path)
        self.tipo = tipo.lower()
        self.encoding = encoding
    
    def load(self) -> Iterator[Dict[str, Any]]:
        fuente, contexto = self.get_source_info()
        
        # Implementaci√≥n espec√≠fica para tu formato
        with open(self.file_path, 'r', encoding=self.encoding) as file:
            content = file.read()
            
            # Procesar contenido seg√∫n tu l√≥gica
            segments = self._process_content(content)
            
            for i, segment in enumerate(segments):
                yield {
                    'text': segment['text'],
                    'is_heading': segment.get('is_heading', False),
                    'fuente': fuente,
                    'contexto': contexto,
                    'fecha': self._extract_date(),
                    'segment_order': i + 1
                }
    
    def _process_content(self, content: str) -> List[Dict[str, Any]]:
        """L√≥gica espec√≠fica de procesamiento."""
        # Implementar seg√∫n el formato
        pass
    
    def _extract_date(self) -> Optional[str]:
        """Extraer fecha del archivo o metadatos."""
        # Implementar extracci√≥n de fecha
        pass
```

#### 2. Registrar el Loader

```python
# En __init__.py del m√≥dulo loaders
from .mi_nuevo_loader import MiNuevoLoader

__all__ = [
    'txtLoader',
    'MarkdownLoader',
    'NDJSONLoader',
    'DocxLoader',
    'PDFLoader',
    'ExcelLoader',
    'CSVLoader',
    'MiNuevoLoader'  # A√±adir aqu√≠
]
```

#### 3. Configurar en ProfileManager

```python
# En ProfileManager.register_default_components()
self.register_loader('.mi_extension', MiNuevoLoader)
```

### Mejores Pr√°cticas para Nuevos Loaders

1. **Herencia consistente**: Siempre heredar de `BaseLoader`
2. **Manejo de errores**: Implementar try/catch para archivos corruptos
3. **Encoding flexible**: Soportar diferentes codificaciones
4. **Metadatos ricos**: Extraer toda la informaci√≥n disponible
5. **Segmentaci√≥n inteligente**: Adaptar seg√∫n el tipo de contenido
6. **Documentaci√≥n completa**: Incluir ejemplos y casos de uso

## üîç Soluci√≥n de Problemas

### Error: "Loader no encontrado"

**Causa**: Extensi√≥n de archivo no registrada

**Soluci√≥n**:
```python
# Verificar loaders registrados
manager = ProfileManager()
print(manager.get_registered_loaders())

# Registrar manualmente si es necesario
manager.register_loader('.mi_ext', MiLoader)
```

### Error: "Encoding no soportado"

**Causa**: Archivo con codificaci√≥n especial

**Soluci√≥n**:
```python
# Detectar encoding autom√°ticamente
import chardet

with open('archivo.txt', 'rb') as f:
    raw_data = f.read()
    encoding = chardet.detect(raw_data)['encoding']
    print(f"Encoding detectado: {encoding}")

# Usar encoding espec√≠fico
loader = txtLoader('archivo.txt', encoding=encoding)
```

### Error: "Archivo muy grande"

**Causa**: Archivo excede memoria disponible

**Soluci√≥n**:
```python
# Procesar en chunks
def process_large_file(file_path, chunk_size=1024*1024):  # 1MB chunks
    with open(file_path, 'r', encoding='utf-8') as f:
        while True:
            chunk = f.read(chunk_size)
            if not chunk:
                break
            # Procesar chunk
            yield process_chunk(chunk)
```

### Error: "Formato no reconocido"

**Causa**: Archivo con formato interno inesperado

**Soluci√≥n**:
```python
# Validar formato antes de procesar
def validate_file_format(file_path):
    try:
        # Intentar abrir con el loader esperado
        loader = get_loader_for_file(file_path)
        first_doc = next(loader.load())
        return True
    except Exception as e:
        print(f"Formato no v√°lido: {e}")
        return False
```

## üìö Recursos Adicionales

### Documentaci√≥n Relacionada

- [**Pipeline NDJSON**](PIPELINE_NDJSON.md) - Flujo completo de procesamiento
- [**Especificaci√≥n NDJSON**](NDJSON_ESPECIFICACION.md) - Formato de salida detallado
- [**Gesti√≥n de Datos**](GUIA_GESTION_DATOS.md) - Importaci√≥n a base de datos

### Ejemplos Pr√°cticos

```python
# Procesamiento por lotes
def process_directory(directory_path, file_pattern="*"):
    from pathlib import Path
    
    directory = Path(directory_path)
    manager = ProfileManager()
    
    for file_path in directory.glob(file_pattern):
        if file_path.is_file():
            print(f"Procesando: {file_path}")
            try:
                results = manager.process_file(str(file_path))
                for result in results:
                    # Procesar resultado
                    save_to_ndjson(result)
            except Exception as e:
                print(f"Error procesando {file_path}: {e}")

# Uso
process_directory("raw_data/mi_autor/", "*.txt")
```

### Configuraci√≥n de Perfiles

```python
# Perfil para libros acad√©micos
academic_profile = {
    "segmentation_strategy": "heading_based",
    "min_segment_length": 100,
    "preserve_citations": True,
    "extract_footnotes": True,
    "heading_levels": [1, 2, 3, 4]
}

# Perfil para poes√≠a
poetry_profile = {
    "segmentation_strategy": "stanza_based",
    "preserve_line_breaks": True,
    "detect_meter": True,
    "whole_file_as_segment": True
}

# Perfil para redes sociales
social_profile = {
    "segmentation_strategy": "message_based",
    "extract_hashtags": True,
    "extract_mentions": True,
    "preserve_timestamps": True
}
```

Esta gu√≠a proporciona todo lo necesario para entender, usar y extender el sistema de loaders de Biblioperson. Para casos espec√≠ficos o problemas no cubiertos, consulta la documentaci√≥n t√©cnica adicional o el c√≥digo fuente de los loaders existentes.