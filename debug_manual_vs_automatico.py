#!/usr/bin/env python3
"""
AnÃ¡lisis: Manual vs AutomÃ¡tico - Â¿Por quÃ© falla la segmentaciÃ³n?

Investiga por quÃ© la selecciÃ³n manual del PDF funciona bien
pero nuestro algoritmo automÃ¡tico solo detecta 75% de los poemas.
"""

import sys
from pathlib import Path
import fitz
import re

# Agregar la ruta del dataset al path
sys.path.append(str(Path(__file__).parent / "dataset"))

from dataset.processing.loaders.pdf_loader import PDFLoader
from dataset.processing.segmenters.verse_segmenter import VerseSegmenter

def analyze_manual_vs_automatic():
    """Compara extracciÃ³n manual vs automÃ¡tica del PDF Neruda"""
    
    pdf_path = r"C:/Users/adven/Downloads/Neruda Pablo_20 Poemas De Amor Y Una Cancion Desesperada.pdf"
    
    if not Path(pdf_path).exists():
        print(f"âŒ PDF no encontrado: {pdf_path}")
        return
        
    print("ğŸ” ANÃLISIS: MANUAL vs AUTOMÃTICO")
    print("=" * 60)
    
    # 1. ANÃLISIS MANUAL DEL PDF
    print("ğŸ“‹ PASO 1: ANÃLISIS MANUAL")
    print("-" * 30)
    
    try:
        doc = fitz.open(pdf_path)
        print(f"ğŸ“„ PÃ¡ginas totales: {len(doc)}")
        
        # Extraer todo el texto pÃ¡gina por pÃ¡gina
        all_text = ""
        for page_num in range(len(doc)):
            page = doc[page_num]
            page_text = page.get_text()
            all_text += page_text + "\n\n"
            
            # Mostrar muestra de cada pÃ¡gina
            lines = page_text.split('\n')
            significant_lines = [line.strip() for line in lines if line.strip() and len(line.strip()) > 3]
            
            print(f"   PÃ¡gina {page_num + 1}: {len(significant_lines)} lÃ­neas significativas")
            if significant_lines:
                print(f"      Primera: '{significant_lines[0][:60]}...'")
                if len(significant_lines) > 1:
                    print(f"      Ãšltima: '{significant_lines[-1][:60]}...'")
        
        doc.close()
        
        # Detectar patrones de poemas manualmente
        manual_poem_patterns = [
            r'^(Poema|POEMA)\s+\d+',  # "Poema 1", "POEMA 2"
            r'^(I|II|III|IV|V|VI|VII|VIII|IX|X|XI|XII|XIII|XIV|XV|XVI|XVII|XVIII|XIX|XX)\.?\s*$',  # NÃºmeros romanos
            r'^\d+\.?\s*$',  # NÃºmeros arÃ¡bigos solos
            r'^[A-Z][A-Z\s]{10,50}$',  # TÃ­tulos largos en mayÃºsculas
            r'.*[Cc]anciÃ³n.*',  # TÃ­tulos con "canciÃ³n"
        ]
        
        manual_titles = []
        for line in all_text.split('\n'):
            line = line.strip()
            if line:
                for pattern in manual_poem_patterns:
                    if re.match(pattern, line):
                        manual_titles.append(line)
                        break
        
        print(f"\nğŸ¯ DETECCIÃ“N MANUAL:")
        print(f"   TÃ­tulos detectados: {len(manual_titles)}")
        for i, title in enumerate(manual_titles[:10], 1):  # Mostrar primeros 10
            print(f"      {i}. {title}")
        if len(manual_titles) > 10:
            print(f"      ... y {len(manual_titles) - 10} mÃ¡s")
        
    except Exception as e:
        print(f"âŒ Error en anÃ¡lisis manual: {e}")
        return
    
    # 2. ANÃLISIS AUTOMÃTICO
    print(f"\nğŸ“‹ PASO 2: ANÃLISIS AUTOMÃTICO")
    print("-" * 30)
    
    try:
        # Usar nuestro PDFLoader
        loader = PDFLoader(pdf_path)
        result = loader.load()
        
        blocks = result.get('blocks', [])
        metadata = result.get('metadata', {})
        
        print(f"ğŸ“¦ Bloques extraÃ­dos: {len(blocks)}")
        print(f"ğŸ“Š Caracteres totales: {metadata.get('char_count', 0)}")
        print(f"ğŸ”§ MÃ©todo extracciÃ³n: {result.get('source_info', {}).get('extraction_method', 'unknown')}")
        
        # Mostrar muestra de bloques
        print(f"\nğŸ“‹ MUESTRA DE BLOQUES:")
        for i, block in enumerate(blocks[:5]):
            text = block.get('text', '')[:100].replace('\n', ' ')
            block_type = block.get('metadata', {}).get('type', 'unknown')
            print(f"   {i+1}. [{block_type}] {text}...")
        
        # Usar VerseSegmenter
        segmenter = VerseSegmenter()
        segments = segmenter.segment(blocks)
        
        print(f"\nğŸ­ SEGMENTACIÃ“N AUTOMÃTICA:")
        print(f"   Segmentos detectados: {len(segments)}")
        
        # Mostrar tÃ­tulos detectados automÃ¡ticamente
        auto_titles = []
        for segment in segments:
            content = segment.get('content', '').strip()
            first_line = content.split('\n')[0].strip() if content else ''
            if first_line:
                auto_titles.append(first_line)
        
        print(f"   Primeros tÃ­tulos automÃ¡ticos:")
        for i, title in enumerate(auto_titles[:10], 1):
            print(f"      {i}. {title[:80]}...")
        
    except Exception as e:
        print(f"âŒ Error en anÃ¡lisis automÃ¡tico: {e}")
        return
    
    # 3. COMPARACIÃ“N Y DIAGNÃ“STICO
    print(f"\nğŸ“Š PASO 3: COMPARACIÃ“N Y DIAGNÃ“STICO")
    print("-" * 30)
    
    print(f"ğŸ¯ RESULTADOS:")
    print(f"   Manual: {len(manual_titles)} tÃ­tulos")
    print(f"   AutomÃ¡tico: {len(segments)} segmentos")
    print(f"   Ratio Ã©xito: {len(segments)/len(manual_titles)*100:.1f}%" if manual_titles else "N/A")
    
    # DiagnÃ³stico de problemas
    print(f"\nğŸ” DIAGNÃ“STICO POTENCIAL:")
    
    if len(segments) < len(manual_titles):
        gap = len(manual_titles) - len(segments)
        print(f"âŒ PROBLEMA: Faltan {gap} segmentos")
        print(f"   Posibles causas:")
        print(f"   â€¢ Bloques demasiado grandes (combinan varios poemas)")
        print(f"   â€¢ Patrones de tÃ­tulos no detectados")
        print(f"   â€¢ Algoritmo de segmentaciÃ³n demasiado conservador")
    
    if len(blocks) < len(doc) * 3:  # Esperamos al menos 3 bloques por pÃ¡gina
        print(f"âŒ PROBLEMA: Muy pocos bloques extraÃ­dos")
        print(f"   â€¢ {len(blocks)} bloques para {len(doc)} pÃ¡ginas")
        print(f"   â€¢ Ratio: {len(blocks)/len(doc):.1f} bloques/pÃ¡gina (esperado: â‰¥3)")
        print(f"   â€¢ Causa: ExtracciÃ³n de texto combina demasiado contenido")
    
    # AnÃ¡lisis de calidad del texto
    sample_text = ' '.join([block.get('text', '') for block in blocks[:3]])
    corruption_chars = sum(1 for char in sample_text if ord(char) < 32 and char not in '\n\r\t')
    corruption_rate = corruption_chars / len(sample_text) * 100 if sample_text else 0
    
    print(f"ğŸ“ CALIDAD DEL TEXTO:")
    print(f"   CorrupciÃ³n: {corruption_rate:.1f}%")
    if corruption_rate > 5:
        print(f"   âš ï¸  Alta corrupciÃ³n detectada - considerar OCR")
    else:
        print(f"   âœ… Texto limpio - problema en segmentaciÃ³n")
    
    print(f"\nğŸ¯ RECOMENDACIONES:")
    if len(segments) < len(manual_titles):
        print(f"   1. ğŸ”§ Mejorar algoritmo de pre-divisiÃ³n de bloques")
        print(f"   2. ğŸ¯ Ampliar patrones de detecciÃ³n de tÃ­tulos")
        print(f"   3. ğŸ“ Reducir umbrales de segmentaciÃ³n")
    
    if len(blocks) < len(doc) * 2:
        print(f"   4. ğŸ“¦ Mejorar granularidad de extracciÃ³n de bloques")
        print(f"   5. ğŸ”„ Usar OCR para mejor granularidad")

if __name__ == "__main__":
    analyze_manual_vs_automatic() 