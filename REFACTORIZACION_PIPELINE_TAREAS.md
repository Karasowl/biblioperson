# üîÑ Refactorizaci√≥n Pipeline Biblioperson - Plan de Tareas

## üìã Estado General del Proyecto
- **Inicio**: [Fecha]
- **Estado**: üü° En Planificaci√≥n
- **Hardware**: i7 14¬™ gen + RTX 4060 8GB
- **Corpus**: ~150GB documentos
- **Chunk target**: 750 caracteres + 200 overlap

---

## üéØ FASE 1: Ingesta y Parsing Unificado
**Objetivo**: Reemplazar loaders/segmenters manuales con unstructured + OCR

### ‚úÖ Tarea 1.1: Investigar e instalar dependencias
- [ ] **Estado**: ‚è≥ Pendiente
- [ ] Instalar `unstructured[all-docs]`
- [ ] Instalar `pdf2image` 
- [ ] Instalar `pytesseract`
- [ ] Configurar Tesseract PATH en Windows
- [ ] Test b√°sico de cada librer√≠a
- **Archivos afectados**: `requirements.txt`, `setup.py`
- **Tiempo estimado**: 2-3 horas

### ‚úÖ Tarea 1.2: Crear m√≥dulo de ingesta unificado
- [ ] **Estado**: ‚è≥ Pendiente
- [ ] Crear `src/pipeline/ingest.py`
- [ ] Funci√≥n `detect_document_type(file_path)` ‚Üí digital vs escaneado
- [ ] Funci√≥n `extract_to_markdown(file_path)` ‚Üí Markdown unificado
- [ ] Soporte OCR para PDFs escaneados
- [ ] Soporte directo para DOCX/EPUB/TXT
- **Archivos afectados**: `src/pipeline/ingest.py` (nuevo)
- **Tiempo estimado**: 8-10 horas

### ‚úÖ Tarea 1.3: Configurar chunking con LangChain
- [ ] **Estado**: ‚è≥ Pendiente
- [ ] Instalar `langchain-text-splitters`
- [ ] Configurar `RecursiveCharacterTextSplitter`
- [ ] Chunk size = 750, overlap = 200
- [ ] Crear `config/chunking.yaml`
- [ ] Test con documentos de diferentes tipos
- **Archivos afectados**: `config/chunking.yaml` (nuevo), `requirements.txt`
- **Tiempo estimado**: 4-5 horas

### ‚úÖ Tarea 1.4: Normalizar procesamiento NDJSON/JSON
- [ ] **Estado**: ‚è≥ Pendiente
- [ ] Stream l√≠nea-a-l√≠nea para NDJSON
- [ ] Extraer solo campo `text` de cada objeto
- [ ] Convertir a Markdown para chunking uniforme
- [ ] Test con archivos grandes (>1GB)
- **Archivos afectados**: `src/pipeline/ingest.py`
- **Tiempo estimado**: 3-4 horas

### ‚úÖ Tarea 1.5: Eliminar loaders/segmenters obsoletos
- [ ] **Estado**: ‚è≥ Pendiente
- [ ] Deprecar `dataset/processing/loaders/`
- [ ] Deprecar `dataset/processing/segmenters/`
- [ ] Migrar tests a nueva implementaci√≥n
- [ ] Actualizar documentaci√≥n
- **Archivos afectados**: `dataset/processing/` (limpieza)
- **Tiempo estimado**: 2-3 horas

---

## üóÑÔ∏è FASE 2: Almacenamiento para Reconstrucci√≥n
**Objetivo**: Redise√±ar esquema SQLite para soporte dual (lectura + b√∫squeda)

### ‚úÖ Tarea 2.1: Dise√±ar nuevo esquema SQLite
- [ ] **Estado**: ‚è≥ Pendiente
- [ ] Tabla `documents` (id, title, author, metadata)
- [ ] Tabla `structural_blocks` (doc_id, order, type, text)
- [ ] √çndices optimizados para consultas
- [ ] Script SQL de creaci√≥n
- **Archivos afectados**: `database/schema_v2.sql` (nuevo)
- **Tiempo estimado**: 3-4 horas

### ‚úÖ Tarea 2.2: Script de migraci√≥n de datos
- [ ] **Estado**: ‚è≥ Pendiente
- [ ] Backup autom√°tico de BD actual
- [ ] Migrar datos existentes al nuevo esquema
- [ ] Validar integridad post-migraci√≥n
- [ ] Script de rollback
- **Archivos afectados**: `scripts/migrate_database.py` (nuevo)
- **Tiempo estimado**: 6-8 horas

### ‚úÖ Tarea 2.3: Implementar persistencia desde unstructured
- [ ] **Estado**: ‚è≥ Pendiente
- [ ] Funci√≥n `save_structural_blocks(doc, elements)`
- [ ] Preservar orden y tipo de elementos
- [ ] Batch insert optimizado (>2000 blocks/s)
- [ ] Manejo de errores y transacciones
- **Archivos afectados**: `src/database/persistence.py`
- **Tiempo estimado**: 5-6 horas

### ‚úÖ Tarea 2.4: Eliminar columnas redundantes
- [ ] **Estado**: ‚è≥ Pendiente
- [ ] Identificar campos obsoletos en esquema actual
- [ ] Limpiar hashes, offsets, flags no utilizados
- [ ] Optimizar tama√±o de BD
- [ ] Documentar cambios
- **Archivos afectados**: `database/schema_v2.sql`
- **Tiempo estimado**: 2-3 horas

---

## üîç FASE 3: Indexaci√≥n Sem√°ntica (RAG)
**Objetivo**: Pipeline de embeddings intercambiable con FAISS local

### ‚úÖ Tarea 3.1: M√≥dulo de embeddings intercambiable
- [ ] **Estado**: ‚è≥ Pendiente
- [ ] Clase `EmbeddingClient` abstracta
- [ ] Backend local: `HuggingFaceEmbeddings` (bge-large-es)
- [ ] Backend cloud: `OpenAIEmbeddings` (text-embedding-3-small)
- [ ] Configuraci√≥n via ENV: `EMBEDDING_BACKEND=local|openai`
- [ ] Auto-detecci√≥n de GPU disponible
- **Archivos afectados**: `src/embeddings/client.py` (nuevo)
- **Tiempo estimado**: 6-8 horas

### ‚úÖ Tarea 3.2: Configurar modelos locales
- [ ] **Estado**: ‚è≥ Pendiente
- [ ] Instalar `sentence-transformers`
- [ ] Descargar `BAAI/bge-large-es` (1024 dims)
- [ ] Test en RTX 4060 (verificar <8GB VRAM)
- [ ] Benchmark: >300 chunks/s
- [ ] Fallback a CPU si GPU no disponible
- **Archivos afectados**: `config/embeddings.yaml` (nuevo)
- **Tiempo estimado**: 4-5 horas

### ‚úÖ Tarea 3.3: Implementar indexaci√≥n FAISS
- [ ] **Estado**: ‚è≥ Pendiente
- [ ] Instalar `faiss-cpu` y `faiss-gpu`
- [ ] Crear √≠ndices FAISS flat L2 por documento
- [ ] Persistencia en `indexes/{doc_id}.faiss`
- [ ] Batch processing optimizado para GPU
- [ ] Procesamiento incremental (solo docs nuevos)
- **Archivos afectados**: `src/search/faiss_index.py` (nuevo)
- **Tiempo estimado**: 8-10 horas

### ‚úÖ Tarea 3.4: Pipeline de chunking para b√∫squeda
- [ ] **Estado**: ‚è≥ Pendiente
- [ ] Concatenar texto de `structural_blocks`
- [ ] Aplicar `RecursiveCharacterTextSplitter`
- [ ] Generar embeddings por chunk
- [ ] Mantener metadatos (doc_id, chunk_index)
- **Archivos afectados**: `src/search/chunking.py`
- **Tiempo estimado**: 4-5 horas

### ‚úÖ Tarea 3.5: B√∫squeda sem√°ntica con re-ranking
- [ ] **Estado**: ‚è≥ Pendiente
- [ ] Funci√≥n `search(query)` ‚Üí embed ‚Üí FAISS top-k
- [ ] Re-ranking opcional con `bge-reranker-large`
- [ ] Configurar k=20 por defecto
- [ ] M√©tricas de similitud y tiempo de respuesta
- [ ] API endpoint `/api/search/semantic`
- **Archivos afectados**: `src/search/semantic.py`, `app/src/app/api/search/semantic/route.ts`
- **Tiempo estimado**: 6-8 horas

---

## üñ•Ô∏è FASE 4: Frontend y Ampliaciones
**Objetivo**: Integrar python-bible y actualizar componentes UI

### ‚úÖ Tarea 4.1: Integrar python-bible
- [ ] **Estado**: ‚è≥ Pendiente
- [ ] Instalar `python-bible`
- [ ] Cargar m√∫ltiples versiones (ESV, RVR60, NVI)
- [ ] Almacenar en esquema unificado (`documents`/`structural_blocks`)
- [ ] Navegaci√≥n por libro/cap√≠tulo/verso
- [ ] API endpoints para consulta b√≠blica
- **Archivos afectados**: `src/bible/`, `app/src/app/api/bible/` (nuevos)
- **Tiempo estimado**: 8-10 horas

### ‚úÖ Tarea 4.2: Actualizar EbookReader
- [ ] **Estado**: ‚è≥ Pendiente
- [ ] Leer desde tabla `structural_blocks`
- [ ] Renderizar elementos por tipo (Title ‚Üí `<h1>`, NarrativeText ‚Üí `<p>`)
- [ ] Preservar orden original del documento
- [ ] Navegaci√≥n fluida entre bloques
- [ ] Soporte para libros b√≠blicos
- **Archivos afectados**: `app/src/components/ebook/EbookReader.tsx`
- **Tiempo estimado**: 6-8 horas

### ‚úÖ Tarea 4.3: Actualizar Chatbot con RAG
- [ ] **Estado**: ‚è≥ Pendiente
- [ ] Integrar b√∫squeda sem√°ntica en chatbot
- [ ] Enviar chunks encontrados como contexto a LLM
- [ ] Mostrar fuentes de informaci√≥n en respuesta
- [ ] UI para ajustar n√∫mero de chunks (k)
- [ ] Historial de conversaci√≥n con contexto
- **Archivos afectados**: `app/src/components/chatbot/`, `app/src/app/api/chat/`
- **Tiempo estimado**: 8-10 horas

### ‚úÖ Tarea 4.4: UI para configuraci√≥n de chunking
- [ ] **Estado**: ‚è≥ Pendiente
- [ ] Slider para chunk size (500-1000 caracteres)
- [ ] Slider para overlap (100-300 caracteres)
- [ ] Preview de chunking en tiempo real
- [ ] Guardar configuraci√≥n por usuario
- [ ] Re-indexar autom√°ticamente si cambian par√°metros
- **Archivos afectados**: `app/src/app/settings/page.tsx`
- **Tiempo estimado**: 4-5 horas

### ‚úÖ Tarea 4.5: Navegaci√≥n b√≠blica avanzada
- [ ] **Estado**: ‚è≥ Pendiente
- [ ] Selector de versi√≥n b√≠blica
- [ ] Navegaci√≥n por libro/cap√≠tulo/verso
- [ ] B√∫squeda por referencia (ej: "Juan 3:16")
- [ ] Comparaci√≥n entre versiones
- [ ] Marcadores y notas en vers√≠culos
- **Archivos afectados**: `app/src/components/bible/` (nuevo)
- **Tiempo estimado**: 10-12 horas

---

## üß™ FASE 5: Testing y Optimizaci√≥n
**Objetivo**: Validar calidad y rendimiento del nuevo pipeline

### ‚úÖ Tarea 5.1: Suite de tests automatizados
- [ ] **Estado**: ‚è≥ Pendiente
- [ ] Tests unitarios para cada m√≥dulo
- [ ] Tests de integraci√≥n end-to-end
- [ ] Tests de rendimiento (GPU/CPU)
- [ ] Tests de calidad de b√∫squeda
- [ ] CI/CD pipeline
- **Archivos afectados**: `tests/` (refactor completo)
- **Tiempo estimado**: 12-15 horas

### ‚úÖ Tarea 5.2: M√©tricas de calidad de b√∫squeda
- [ ] **Estado**: ‚è≥ Pendiente
- [ ] Dataset de queries de prueba (Plat√≥n, poes√≠a, Biblia)
- [ ] M√©tricas: Recall@10, Precision@10, MRR
- [ ] Comparaci√≥n: sistema actual vs nuevo
- [ ] Target: Recall@10 ‚â• 90%
- [ ] Dashboard de m√©tricas
- **Archivos afectados**: `tests/evaluation/` (nuevo)
- **Tiempo estimado**: 8-10 horas

### ‚úÖ Tarea 5.3: Optimizaci√≥n de rendimiento
- [ ] **Estado**: ‚è≥ Pendiente
- [ ] Profiling de memoria y CPU
- [ ] Optimizaci√≥n de batch processing
- [ ] Cache de embeddings frecuentes
- [ ] Compresi√≥n de √≠ndices FAISS
- [ ] Target: <500ms por b√∫squeda
- **Archivos afectados**: M√∫ltiples archivos de optimizaci√≥n
- **Tiempo estimado**: 10-12 horas

### ‚úÖ Tarea 5.4: Documentaci√≥n y limpieza
- [ ] **Estado**: ‚è≥ Pendiente
- [ ] Actualizar README con nuevo pipeline
- [ ] Documentar APIs y configuraci√≥n
- [ ] Gu√≠as de instalaci√≥n y uso
- [ ] Eliminar c√≥digo obsoleto
- [ ] Changelog detallado
- **Archivos afectados**: `docs/`, `README.md`
- **Tiempo estimado**: 6-8 horas

---

## üìä Resumen de Progreso

### Por Fase
- **FASE 1** (Ingesta): 0/5 tareas completadas (0%)
- **FASE 2** (Almacenamiento): 0/4 tareas completadas (0%)
- **FASE 3** (RAG): 0/5 tareas completadas (0%)
- **FASE 4** (Frontend): 0/5 tareas completadas (0%)
- **FASE 5** (Testing): 0/4 tareas completadas (0%)

### Total General
**0/23 tareas completadas (0%)**

### Tiempo Estimado Total
**140-180 horas** (aproximadamente 4-6 semanas a tiempo completo)

---

## üîß Dependencias T√©cnicas a Instalar

```bash
# Procesamiento de documentos
pip install unstructured[all-docs]
pip install pdf2image
pip install pytesseract

# LangChain y chunking
pip install langchain-text-splitters
pip install langchain-community

# Embeddings y b√∫squeda
pip install sentence-transformers
pip install faiss-cpu faiss-gpu
pip install transformers torch

# Biblia
pip install python-bible

# Utilidades
pip install huggingface-hub
pip install numpy pandas
```

---

## üìù Notas de Implementaci√≥n

### Prioridades
1. **FASE 1** es cr√≠tica - sin esto no avanzamos
2. **FASE 3** es el coraz√≥n del sistema - embeddings y b√∫squeda
3. **FASE 2** puede hacerse en paralelo con FASE 3
4. **FASE 4** depende de FASE 2 completada
5. **FASE 5** es continua durante todo el proyecto

### Riesgos Identificados
- ‚ö†Ô∏è **GPU Memory**: Verificar que bge-large-es cabe en 8GB
- ‚ö†Ô∏è **Migraci√≥n de datos**: Backup obligatorio antes de cambiar esquema
- ‚ö†Ô∏è **Rendimiento**: Puede requerir optimizaciones adicionales
- ‚ö†Ô∏è **Calidad**: Sistema actual podr√≠a ser mejor en algunos casos

### Checkpoints de Validaci√≥n
- [ ] **Checkpoint 1**: Pipeline b√°sico funciona con un documento
- [ ] **Checkpoint 2**: Migraci√≥n de BD completada sin p√©rdidas
- [ ] **Checkpoint 3**: B√∫squeda sem√°ntica supera sistema actual
- [ ] **Checkpoint 4**: UI integrada y funcional
- [ ] **Checkpoint 5**: Tests pasan y m√©tricas son satisfactorias

---

*√öltima actualizaci√≥n: [Fecha]*
*Pr√≥xima revisi√≥n: [Fecha]* 