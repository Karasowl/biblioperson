#!/usr/bin/env python3
"""
Algoritmo Avanzado de Detecci√≥n Autom√°tica de Autores
====================================================

Sistema multi-nivel para identificar autom√°ticamente autores en textos de verso y prosa.
Utiliza patrones regex, an√°lisis de contexto, frecuencia y scoring de confianza.

Autor: Sistema Biblioperson
Versi√≥n: 1.0.0
"""

import re
import logging
from typing import Dict, List, Any, Optional, Tuple, Set
from collections import Counter, defaultdict
from dataclasses import dataclass
import unicodedata

logger = logging.getLogger(__name__)

@dataclass
class AuthorCandidate:
    """Candidato a autor con metadata"""
    name: str
    confidence: float
    sources: List[str]  # Donde se encontr√≥
    positions: List[int]  # Posiciones en el texto
    extraction_method: str
    context: List[str]  # Contexto alrededor

class AutorDetector:
    """
    Detector avanzado de autores para textos de verso y prosa.
    
    Implementa un algoritmo multi-nivel:
    1. Extracci√≥n de metadatos estructurados
    2. An√°lisis de patrones textuales espec√≠ficos
    3. An√°lisis de contexto y frecuencia
    4. Scoring y validaci√≥n final
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """
        Inicializar el detector de autores.
        
        Args:
            config: Configuraci√≥n opcional del detector
        """
        self.config = config or {}
        self.confidence_threshold = self.config.get('confidence_threshold', 0.6)
        self.debug_mode = self.config.get('debug', False)
        
        # Configurar logging
        self.logger = logging.getLogger(f"{__name__}.AutorDetector")
        if self.debug_mode:
            self.logger.setLevel(logging.DEBUG)
            
        self.logger.info("üîç INICIALIZANDO AUTOR DETECTOR V1.0 - ALGORITMO AVANZADO")
        
        # === NIVEL 1: PATRONES DE METADATOS EXPL√çCITOS ===
        self.metadata_patterns = {
            'explicit_author': [
                r'(?:^|\n)\s*(?:Autor|Author|Por|By|Escrito por|Written by):\s*([A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+(?:\s+[A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+){1,3})',
                r'(?:^|\n)\s*([A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+(?:\s+[A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+){1,3})\s*\(autor\)',
                r'(?:^|\n)\s*¬©\s*([A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+(?:\s+[A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+){1,3})',
            ],
            'byline_patterns': [
                r'(?:^|\n)\s*(?:Por|By)\s+([A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+(?:\s+[A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+){1,3})\s*(?:\n|$)',
                r'(?:^|\n)\s*([A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+(?:\s+[A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+){1,3})\s*[-‚Äì‚Äî]\s*\d{4}',
            ]
        }
        
        # === NIVEL 2A: PATRONES ESPEC√çFICOS PARA VERSO (POES√çA) ===
        self.verso_patterns = {
            'signature_end': [
                r'(?:^|\n)\s*‚Äî\s*([A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+(?:\s+[A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+){1,3})\s*$',
                r'(?:^|\n)\s*[-‚Äì‚Äî]\s*([A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+(?:\s+[A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+){1,3})\s*$',
            ],
            'attribution_verse': [
                r'(?:^|\n)\s*(?:De|Por)\s+([A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+(?:\s+[A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+){1,3})\s*$',
                r'(?:^|\n)\s*([A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+(?:\s+[A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+){1,3})\s*\([Aa]utor\)',
            ],
            'poem_title_author': [
                r'(?:Soneto|Canci√≥n|Eleg√≠a|Oda|Balada|Poema)\s+(?:de\s+)?([A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+(?:\s+[A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+){1,3})',
                r'^([A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+(?:\s+[A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+){1,3})\s*\(poem[as]?\)',
            ],
            'isolated_name': [
                r'(?:^|\n)\s*([A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+(?:\s+[A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+){1,3})\s*(?:\n|$)',
            ]
        }
        
        # === NIVEL 2B: PATRONES ESPEC√çFICOS PARA PROSA ===
        self.prosa_patterns = {
            'academic_format': [
                r'([A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+(?:\s+[A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+){1,3})\s*\(\d{4}\)',
                r'([A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+),\s+([A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+(?:\s+[A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+){0,2})\s*\(\d{4}\)',
            ],
            'article_header': [
                r'(?:^|\n)\s*([A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+(?:\s+[A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+){1,3})\s*[-‚Äì‚Äî]\s*\d{1,2}/\d{1,2}/\d{4}',
                r'(?:^|\n)\s*\*\*([A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+(?:\s+[A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+){1,3})\*\*',
            ],
            'book_author': [
                r'(?:^|\n)\s*([A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+(?:\s+[A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+){1,3})\s*\n.*(?:ISBN|Edici√≥n|Editorial)',
                r'Editorial.*\n.*([A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+(?:\s+[A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+){1,3})',
            ]
        }
        
        # === NIVEL 3: LISTA DE PALABRAS NO V√ÅLIDAS COMO NOMBRES ===
        self.invalid_names = {
            # Art√≠culos, preposiciones, conjunciones
            'el', 'la', 'los', 'las', 'un', 'una', 'unos', 'unas',
            'de', 'del', 'en', 'con', 'por', 'para', 'desde', 'hasta',
            'sobre', 'bajo', 'ante', 'tras', 'durante', 'mediante',
            'y', 'o', 'pero', 'sino', 'aunque', 'porque', 'como', 'cuando',
            # Palabras comunes que no son nombres
            'se√±or', 'se√±ora', 'don', 'do√±a', 'casa', 'vida', 'mundo',
            'tiempo', 'hombre', 'mujer', 'd√≠a', 'noche', 'amor', 'muerte',
            'dios', 'cristo', 'virgen', 'santo', 'santa', 'san',
            # Meses y d√≠as
            'enero', 'febrero', 'marzo', 'abril', 'mayo', 'junio',
            'julio', 'agosto', 'septiembre', 'octubre', 'noviembre', 'diciembre',
            'lunes', 'martes', 'mi√©rcoles', 'jueves', 'viernes', 's√°bado', 'domingo',
            # Palabras t√©cnicas
            'p√°gina', 'cap√≠tulo', 't√≠tulo', '√≠ndice', 'pr√≥logo', 'ep√≠logo',
            'introducci√≥n', 'conclusi√≥n', 'anexo', 'ap√©ndice', 'bibliograf√≠a'
        }
        
        # === COMPILAR PATRONES REGEX ===
        self._compile_patterns()
        
        self.logger.info(f"‚úÖ Detector configurado - umbral: {self.confidence_threshold}")
    
    def _compile_patterns(self) -> None:
        """Compilar todos los patrones regex para mayor eficiencia"""
        self.compiled_patterns = {}
        
        # Compilar patrones de metadatos
        for category, patterns in self.metadata_patterns.items():
            self.compiled_patterns[category] = [re.compile(p, re.MULTILINE | re.IGNORECASE) for p in patterns]
        
        # Compilar patrones de verso
        for category, patterns in self.verso_patterns.items():
            self.compiled_patterns[f"verso_{category}"] = [re.compile(p, re.MULTILINE | re.IGNORECASE) for p in patterns]
        
        # Compilar patrones de prosa
        for category, patterns in self.prosa_patterns.items():
            self.compiled_patterns[f"prosa_{category}"] = [re.compile(p, re.MULTILINE | re.IGNORECASE) for p in patterns]
    
    def detect_author(self, segments: List[Dict[str, Any]], profile_type: str) -> Optional[Dict[str, Any]]:
        """
        Detectar autom√°ticamente el autor en una lista de segmentos.
        
        Args:
            segments: Lista de segmentos de texto procesados
            profile_type: Tipo de perfil ('verso' o 'prosa')
            
        Returns:
            Diccionario con informaci√≥n del autor detectado o None
        """
        if not segments:
            return None
        
        self.logger.info(f"üîç INICIANDO DETECCI√ìN DE AUTOR - Perfil: {profile_type}, Segmentos: {len(segments)}")
        
        # Unir todo el texto para an√°lisis global
        full_text = self._combine_segments_text(segments)
        if not full_text:
            return None
        
        candidates = []
        
        # === NIVEL 1: METADATOS EXPL√çCITOS ===
        metadata_candidates = self._extract_metadata_authors(full_text)
        candidates.extend(metadata_candidates)
        self.logger.debug(f"Nivel 1 - Metadatos: {len(metadata_candidates)} candidatos")
        
        # === NIVEL 2: PATRONES ESPEC√çFICOS POR TIPO ===
        if profile_type == 'verso':
            type_candidates = self._detect_verse_authors(full_text, segments)
        elif profile_type == 'prosa':
            type_candidates = self._detect_prose_authors(full_text, segments)
        else:
            type_candidates = []
        
        candidates.extend(type_candidates)
        self.logger.debug(f"Nivel 2 - Patrones espec√≠ficos: {len(type_candidates)} candidatos")
        
        # === NIVEL 3: SCORING Y VALIDACI√ìN ===
        if not candidates:
            self.logger.info("‚ùå No se encontraron candidatos de autor")
            return None
        
        scored_candidates = self._score_candidates(candidates, segments, full_text)
        
        # === NIVEL 4: SELECCI√ìN FINAL ===
        best_author = self._select_best_author(scored_candidates)
        
        if best_author:
            self.logger.info(f"‚úÖ AUTOR DETECTADO: '{best_author['name']}' (confianza: {best_author['confidence']:.2f})")
            return best_author
        else:
            self.logger.info("‚ùå No se pudo determinar autor con suficiente confianza")
            return None
    
    def _combine_segments_text(self, segments: List[Dict[str, Any]]) -> str:
        """Combinar el texto de todos los segmentos para an√°lisis global"""
        texts = []
        for segment in segments:
            text = segment.get('text', '') or segment.get('content', '')
            if text:
                texts.append(text.strip())
        return '\n\n'.join(texts)
    
    def _extract_metadata_authors(self, text: str) -> List[AuthorCandidate]:
        """NIVEL 1: Extraer autores de metadatos expl√≠citos"""
        candidates = []
        
        for category, compiled_patterns in self.compiled_patterns.items():
            if not category.startswith(('verso_', 'prosa_')):
                for pattern in compiled_patterns:
                    matches = pattern.finditer(text)
                    for match in matches:
                        name = self._clean_author_name(match.group(1))
                        if self._is_valid_name(name):
                            candidates.append(AuthorCandidate(
                                name=name,
                                confidence=0.0,  # Se calcular√° despu√©s
                                sources=[category],
                                positions=[match.start()],
                                extraction_method='metadata',
                                context=[self._get_context(text, match.start(), match.end())]
                            ))
        
        return candidates
    
    def _detect_verse_authors(self, text: str, segments: List[Dict[str, Any]]) -> List[AuthorCandidate]:
        """NIVEL 2A: Detectar autores espec√≠ficos en textos de verso"""
        candidates = []
        
        for category, compiled_patterns in self.compiled_patterns.items():
            if category.startswith('verso_'):
                for pattern in compiled_patterns:
                    matches = pattern.finditer(text)
                    for match in matches:
                        name = self._clean_author_name(match.group(1))
                        if self._is_valid_name(name):
                            candidates.append(AuthorCandidate(
                                name=name,
                                confidence=0.0,
                                sources=[category],
                                positions=[match.start()],
                                extraction_method='verse_pattern',
                                context=[self._get_context(text, match.start(), match.end())]
                            ))
        
        return candidates
    
    def _detect_prose_authors(self, text: str, segments: List[Dict[str, Any]]) -> List[AuthorCandidate]:
        """NIVEL 2B: Detectar autores espec√≠ficos en textos de prosa"""
        candidates = []
        
        for category, compiled_patterns in self.compiled_patterns.items():
            if category.startswith('prosa_'):
                for pattern in compiled_patterns:
                    matches = pattern.finditer(text)
                    for match in matches:
                        # Algunos patrones de prosa pueden capturar m√∫ltiples grupos
                        for i in range(1, len(match.groups()) + 1):
                            try:
                                name = self._clean_author_name(match.group(i))
                                if self._is_valid_name(name):
                                    candidates.append(AuthorCandidate(
                                        name=name,
                                        confidence=0.0,
                                        sources=[category],
                                        positions=[match.start()],
                                        extraction_method='prose_pattern',
                                        context=[self._get_context(text, match.start(), match.end())]
                                    ))
                                    break  # Solo tomar el primer nombre v√°lido del match
                            except IndexError:
                                break
        
        return candidates
    
    def _score_candidates(self, candidates: List[AuthorCandidate], 
                         segments: List[Dict[str, Any]], full_text: str) -> List[AuthorCandidate]:
        """NIVEL 3: Calcular score de confianza para cada candidato"""
        
        # Agrupar candidatos por nombre
        name_groups = defaultdict(list)
        for candidate in candidates:
            normalized_name = self._normalize_name(candidate.name)
            name_groups[normalized_name].append(candidate)
        
        scored_candidates = []
        
        for normalized_name, group in name_groups.items():
            # Combinar informaci√≥n de todos los candidatos del mismo nombre
            combined_candidate = self._combine_candidates(group)
            
            # Calcular score
            score = self._calculate_candidate_score(combined_candidate, segments, full_text)
            combined_candidate.confidence = score
            
            self.logger.debug(f"Candidato '{combined_candidate.name}' ‚Üí Score: {score:.3f}")
            
            scored_candidates.append(combined_candidate)
        
        # Ordenar por score descendente
        scored_candidates.sort(key=lambda c: c.confidence, reverse=True)
        
        return scored_candidates
    
    def _combine_candidates(self, candidates: List[AuthorCandidate]) -> AuthorCandidate:
        """Combinar m√∫ltiples candidatos del mismo nombre"""
        if len(candidates) == 1:
            return candidates[0]
        
        # Tomar el nombre m√°s com√∫n/completo
        names = [c.name for c in candidates]
        name_counter = Counter(names)
        best_name = name_counter.most_common(1)[0][0]
        
        # Combinar sources, positions y context
        all_sources = []
        all_positions = []
        all_context = []
        extraction_methods = []
        
        for candidate in candidates:
            all_sources.extend(candidate.sources)
            all_positions.extend(candidate.positions)
            all_context.extend(candidate.context)
            extraction_methods.append(candidate.extraction_method)
        
        return AuthorCandidate(
            name=best_name,
            confidence=0.0,  # Se calcular√° despu√©s
            sources=list(set(all_sources)),
            positions=all_positions,
            extraction_method='|'.join(set(extraction_methods)),
            context=all_context
        )
    
    def _calculate_candidate_score(self, candidate: AuthorCandidate, 
                                 segments: List[Dict[str, Any]], full_text: str) -> float:
        """Calcular score de confianza para un candidato"""
        score = 0.0
        
        # === FACTOR 1: M√âTODO DE EXTRACCI√ìN (0.0 - 0.4) ===
        if 'metadata' in candidate.extraction_method:
            score += 0.4  # Metadatos expl√≠citos son m√°s confiables
        elif 'verse_pattern' in candidate.extraction_method:
            if any('signature' in source for source in candidate.sources):
                score += 0.35  # Firmas en versos
            elif any('attribution' in source for source in candidate.sources):
                score += 0.3   # Atribuciones
            else:
                score += 0.25  # Otros patrones de verso
        elif 'prose_pattern' in candidate.extraction_method:
            if any('academic' in source for source in candidate.sources):
                score += 0.3   # Formato acad√©mico
            elif any('header' in source for source in candidate.sources):
                score += 0.25  # Headers de art√≠culos
            else:
                score += 0.2   # Otros patrones de prosa
        
        # === FACTOR 2: FRECUENCIA DE APARICI√ìN (0.0 - 0.3) ===
        frequency = len(candidate.positions)
        if frequency >= 3:
            score += 0.3
        elif frequency == 2:
            score += 0.2
        else:
            score += 0.1
        
        # === FACTOR 3: POSICI√ìN EN EL TEXTO (0.0 - 0.2) ===
        text_length = len(full_text)
        for position in candidate.positions:
            relative_position = position / text_length
            if relative_position <= 0.1 or relative_position >= 0.9:  # Inicio o final
                score += 0.2 / len(candidate.positions)  # Distribuir entre posiciones
            elif relative_position <= 0.2 or relative_position >= 0.8:  # Cerca del inicio/final
                score += 0.1 / len(candidate.positions)
        
        # === FACTOR 4: VALIDACI√ìN COMO NOMBRE PROPIO (0.0 - 0.1) ===
        if self._is_proper_name_format(candidate.name):
            score += 0.1
        
        # Asegurar que el score est√© entre 0 y 1
        return min(score, 1.0)
    
    def _select_best_author(self, scored_candidates: List[AuthorCandidate]) -> Optional[Dict[str, Any]]:
        """NIVEL 4: Seleccionar el mejor candidato basado en el score"""
        if not scored_candidates:
            return None
        
        best_candidate = scored_candidates[0]
        
        if best_candidate.confidence >= self.confidence_threshold:
            return {
                'name': best_candidate.name,
                'confidence': best_candidate.confidence,
                'extraction_method': best_candidate.extraction_method,
                'sources': best_candidate.sources,
                'frequency': len(best_candidate.positions),
                'positions': best_candidate.positions,
                'detection_details': {
                    'total_candidates': len(scored_candidates),
                    'threshold_used': self.confidence_threshold,
                    'context_samples': best_candidate.context[:3]  # Primeros 3 contextos
                }
            }
        
        return None
    
    def _clean_author_name(self, name: str) -> str:
        """Limpiar y normalizar nombre de autor"""
        if not name:
            return ""
        
        # Eliminar espacios extra y normalizar
        cleaned = re.sub(r'\s+', ' ', name.strip())
        
        # Eliminar caracteres especiales al inicio/final
        cleaned = re.sub(r'^[^\w\s]+|[^\w\s]+$', '', cleaned)
        
        # Capitalizar correctamente
        words = cleaned.split()
        capitalized_words = []
        for word in words:
            if len(word) > 1:
                capitalized_words.append(word.capitalize())
            else:
                capitalized_words.append(word.upper())
        
        return ' '.join(capitalized_words)
    
    def _is_valid_name(self, name: str) -> bool:
        """Validar si una cadena es un nombre v√°lido"""
        if not name or len(name) < 3:
            return False
        
        # Normalizar para comparaci√≥n
        normalized = self._normalize_name(name)
        words = normalized.lower().split()
        
        # Rechazar si contiene palabras inv√°lidas
        for word in words:
            if word in self.invalid_names:
                return False
        
        # Debe tener al menos una palabra que parezca nombre
        if len(words) < 2:
            return False
        
        # Verificar formato b√°sico de nombre
        if not re.match(r'^[A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+(?:\s+[A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+)+$', name):
            return False
        
        return True
    
    def _is_proper_name_format(self, name: str) -> bool:
        """Verificar si tiene formato de nombre propio"""
        words = name.split()
        
        # Al menos 2 palabras
        if len(words) < 2:
            return False
        
        # Todas las palabras deben estar capitalizadas
        for word in words:
            if not word[0].isupper():
                return False
        
        # No m√°s de 4 palabras (nombres muy largos son sospechosos)
        if len(words) > 4:
            return False
        
        return True
    
    def _normalize_name(self, name: str) -> str:
        """Normalizar nombre para comparaci√≥n"""
        # Remover acentos
        normalized = unicodedata.normalize('NFD', name)
        normalized = ''.join(c for c in normalized if unicodedata.category(c) != 'Mn')
        
        # Convertir a min√∫sculas para comparaci√≥n
        return normalized.lower().strip()
    
    def _get_context(self, text: str, start: int, end: int, window: int = 50) -> str:
        """Obtener contexto alrededor de una coincidencia"""
        context_start = max(0, start - window)
        context_end = min(len(text), end + window)
        
        context = text[context_start:context_end]
        
        # Agregar indicadores si se trunc√≥
        if context_start > 0:
            context = "..." + context
        if context_end < len(text):
            context = context + "..."
        
        return context.replace('\n', ' ').strip()

# === FUNCIONES DE UTILIDAD PARA INTEGRACI√ìN ===

def detect_author_in_segments(segments: List[Dict[str, Any]], 
                            profile_type: str,
                            config: Optional[Dict[str, Any]] = None) -> Optional[Dict[str, Any]]:
    """
    Funci√≥n de conveniencia para detectar autor en segmentos.
    
    Args:
        segments: Lista de segmentos procesados
        profile_type: Tipo de perfil ('verso' o 'prosa')
        config: Configuraci√≥n opcional del detector
        
    Returns:
        Informaci√≥n del autor detectado o None
    """
    detector = AutorDetector(config)
    return detector.detect_author(segments, profile_type)

def get_author_detection_config(profile_type: str) -> Dict[str, Any]:
    """
    Obtener configuraci√≥n por defecto para detecci√≥n de autores.
    
    Args:
        profile_type: Tipo de perfil ('verso' o 'prosa')
        
    Returns:
        Configuraci√≥n recomendada
    """
    base_config = {
        'confidence_threshold': 0.6,
        'debug': False
    }
    
    if profile_type == 'verso':
        base_config.update({
            'confidence_threshold': 0.5,  # M√°s permisivo para poes√≠a
        })
    elif profile_type == 'prosa':
        base_config.update({
            'confidence_threshold': 0.7,  # M√°s estricto para prosa
        })
    
    return base_config 